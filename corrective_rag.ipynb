{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3a2dd9b",
   "metadata": {},
   "source": [
    "### Corrective RAG implementation with LangChain & LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d48a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import os\n",
    "\n",
    "# set enviroment variables for tracing and web-search\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ['TAVILY_API_KEY'] = \"***Insert your API key***\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"***Insert your API key***\"\n",
    "\n",
    "os.environ['TAVILY_API_KEY'] = \"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\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff6827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define local embedding-model\n",
    "embedding_model = OllamaEmbeddings(model= 'nomic-embed-text:latest')\n",
    "\n",
    "# define local LLM\n",
    "llm = ChatOllama(model = \"mistral:latest\", temperature= 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data sources\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs = [item for doc in docs for item in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32414734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splittting & chunking\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size= 250, chunk_overlap= 20)\n",
    "doc_chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2492d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the vectorstore and indexing the chunks\n",
    "vectorstore = Chroma.from_documents(documents= doc_chunks, embedding= embedding_model, \n",
    "                                    collection_name= \"crag\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build document grader chain\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GraderSchema(BaseModel):\n",
    "    response : str = Field(description= \"Assess if retrieved documents are relevant to the question: 'yes' or 'no'\")\n",
    "\n",
    "system_template = \"You are an expert at assessing if the retrieved documents are semantically relevant to the question being asked. Answer your question with a simple 'yes' or 'no'\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "                            (\"system\", system_template),\n",
    "                            (\"human\", \"Retrieved documents:{context}\\n\\nQuestion:{question}\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef404e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ = llm.with_structured_output(GraderSchema)\n",
    "relevance_chain = (prompt | llm_ | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba701375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likhi\\AppData\\Local\\Temp\\ipykernel_26904\\2641462882.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(\"What is an AI agent?\")\n"
     ]
    }
   ],
   "source": [
    "relevant_docs = retriever.get_relevant_documents(\"What is an AI agent?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cceaef7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Given the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be'),\n",
       " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Agent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:'),\n",
       " Document(metadata={'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Here is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "938a9a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraderSchema(response='No')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_chain.invoke({\"context\": relevant_docs[0].page_content, \"question\": \"what is theory of relativity?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6c0411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \"What is the concept of model distillation in the context of Language Model Learning (LLM)?\"'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question rewriter\n",
    "template = \"You are an expert at rewriting questions to make web search easier.Simply output the rephrased question.\\nQuestion: {question}\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rewriting_chain = (prompt | llm | StrOutputParser())\n",
    "rewriting_chain.invoke({'question': \"Explain model distillation in llm\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88011460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define web-search tool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "web_search = TavilySearchResults(max_results= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6c003fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = web_search.invoke({'query': \"What does AWS do?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e783cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Amazon Web Services - Wikipedia',\n",
       "  'url': 'https://en.wikipedia.org/wiki/Amazon_Web_Services',\n",
       "  'content': '**Amazon Web Services, Inc.** (**AWS**) is a subsidiary of [Amazon](/wiki/Amazon.com \"Amazon.com\") that provides [on-demand](/wiki/Software_as_a_service \"Software as a service\") [cloud computing](/wiki/Cloud_computing \"Cloud computing\") [platforms](/wiki/Computing_platform \"Computing platform\") and [APIs](/wiki/Application_programming_interface \"Application programming interface\") to individuals, companies, and governments, on a metered, pay-as-you-go basis. Clients will often use this in',\n",
       "  'score': 0.81418616},\n",
       " {'title': 'What Is Amazon Web Services, and Why Is It So Successful?',\n",
       "  'url': 'https://www.investopedia.com/articles/investing/011316/what-amazon-web-services-and-why-it-so-successful.asp',\n",
       "  'content': 'AWS is made up of many different cloud computing products and services. They provide servers, storage, networking, remote computing, email, mobile development, and security.\\n\\n## How Does AWS Do It for Less?\\n\\nCompanies pay AWS for what they use, with costs scaled automatically and accordingly. There’s no storage system to build and no usage to estimate.\\n\\n## How Is AWS Secure? [...] AWS is made up of many different [cloud computing](https://www.investopedia.com/terms/c/cloud-computing.asp) products and services. The highly profitable division of Amazon provides servers, storage, networking, remote computing, email, mobile development, and security. AWS can be broken into three main products: EC2, Amazon’s virtual machine service; Glacier, a low-cost cloud storage service; and S3, Amazon’s storage system.',\n",
       "  'score': 0.78866494},\n",
       " {'title': 'Introduction to Amazon Web Services - GeeksforGeeks',\n",
       "  'url': 'https://www.geeksforgeeks.org/introduction-to-amazon-web-services/',\n",
       "  'content': \"Amazon Web Services (AWS) is one of the world's leading cloud platforms in providing the web services of various domains. AWS follows the trends of digital IT and comes up needy services with optimized performances covering a wide range of services from Compute to Storage. It covers a wider range of customers of different domains to expand their business operations. This Article covers the fundamentals of AWS and its scope of IT business.\\n\\nTable of Content [...] and much more. AWS facilitates for both businesses and individual users with effectively hosting the applications, storing the data securely, and making use of a wide variety of tools and services improving management flexibility for IT resources. [...] *   [Introduction to Amazon Web Services Amazon Web Services (AWS) is one of the world's leading cloud platforms in providing the web services of various domains. AWS follows the trends of digital IT and comes up needy services with optimized performances covering a wide range of services from Compute to Storage. It covers a wider range of 12 min read](https://www.geeksforgeeks.org/introduction-to-amazon-web-services/)\",\n",
       "  'score': 0.77751994}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b700fb",
   "metadata": {},
   "source": [
    "##### Define Graph State - for LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f2743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "# a pydantic base class\n",
    "class StateSchema(BaseModel):\n",
    "\n",
    "    question: str\n",
    "    documents: Optional[List[Document]] = list()\n",
    "    generation: Optional[str] = None\n",
    "    web_search: Optional[str] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebb977e",
   "metadata": {},
   "source": [
    "#### Define Graph Nodes and their functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a674f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state):\n",
    "\n",
    "    \"\"\"Retrieves relevant documents from vectorstore and returns the updated state\"\"\"\n",
    "\n",
    "    question = state.question\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    state.documents.extend(retrieved_docs)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ad4dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state):\n",
    "\n",
    "    \"\"\"Generates output based on the context and query given to the LLM\"\"\"\n",
    "\n",
    "    question = state.question\n",
    "    retrieved_docs = state.documents\n",
    "\n",
    "    template = \"\"\"You are an expert at directly answering questions based on the given context.\\n\\nContext: {context}\\n\\nQuestion:{question}\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    generation_chain = (prompt | llm | StrOutputParser())\n",
    "\n",
    "    state.generation = generation_chain.invoke({\"context\": retrieved_docs, \"question\": question})\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c0139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_documents(state):\n",
    "\n",
    "    \"\"\"Assigns relevancy label to a specific retrieved document. If any retrieved doc is irrelevant we use web-search\"\"\"\n",
    "\n",
    "    question = state.question\n",
    "    documents = state.documents\n",
    "    relevant_docs = list()\n",
    "    web_search = \"no\"\n",
    "\n",
    "    for doc in documents:\n",
    "\n",
    "        ai_output = relevance_chain.invoke({'question':question, \"context\": doc.page_content})\n",
    "\n",
    "        if ai_output.response.lower() == \"yes\":\n",
    "            relevant_docs.append(doc)\n",
    "        \n",
    "        else:\n",
    "            web_search = \"yes\"\n",
    "        \n",
    "    state.web_search = web_search\n",
    "    state.documents = relevant_docs\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_query(state):\n",
    "\n",
    "    \"\"\"If web-search is requested, then it transforms the query into a better structure suitable for web-search\"\"\"\n",
    "\n",
    "    question = state.question\n",
    "\n",
    "    better_question = rewriting_chain.invoke({\"question\": question})\n",
    "\n",
    "    state.question = better_question\n",
    "\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a78298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_generate(state):\n",
    "\n",
    "    \"\"\"Conditional-edge in the LangGraph structure that decide whether to proceed with generation or transform the query and perform web-search\"\"\"\n",
    "\n",
    "    web_search = state.web_search\n",
    "\n",
    "    if web_search.lower() == \"yes\":\n",
    "        return \"transform\"\n",
    "    else:\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe38e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def internet_search(state):\n",
    "\n",
    "    \"\"\"Perofrm Tavily web search and add the top 3 search result contents as Documents\"\"\"\n",
    "\n",
    "    web_search = state.web_search\n",
    "    query = state.question\n",
    "    relevant_docs = list()\n",
    "    \n",
    "\n",
    "    if web_search.lower().strip() == \"yes\":\n",
    "        search_tool = TavilySearchResults(max_results= 3)\n",
    "        search_results = search_tool.invoke({\"query\": query})\n",
    "\n",
    "        for source in search_results:\n",
    "            content = source['content']\n",
    "            doc = Document(page_content= content)\n",
    "            relevant_docs.append(doc)\n",
    "\n",
    "    state.documents = relevant_docs\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4dbfe",
   "metadata": {},
   "source": [
    "#### Define LangGraph graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State graph is a graph where the nodes communicate with each other by modifying a certain state\n",
    "from langgraph.graph import StateGraph, START, END \n",
    "\n",
    "graph = StateGraph(StateSchema)\n",
    "\n",
    "graph.add_node(\"retrieve\", retrieve)\n",
    "graph.add_node(\"generate\", generate)\n",
    "graph.add_node(\"transform_query\", transform_query)\n",
    "graph.add_node(\"grade_documents\", grade_documents)\n",
    "graph.add_node(\"internet_search\", internet_search)\n",
    "\n",
    "graph.add_edge(START, \"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"grade_documents\")\n",
    "graph.add_conditional_edges(\"grade_documents\", \n",
    "                            to_generate, \n",
    "                            {\"transform\": \"transform_query\",\n",
    "                             \"generate\":\"generate\"})\n",
    "\n",
    "graph.add_edge(\"transform_query\", \"internet_search\")\n",
    "graph.add_edge(\"internet_search\", \"generate\")\n",
    "graph.add_edge(\"generate\", END)\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "57d5e190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The winning team of the 2023 ICC World Cup is Australia.'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = workflow.invoke({\"question\": \"Who is the ICC Champion in 2023?\"})\n",
    "results['generation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d3692b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '2023 ICC World Cup Champions: Identify the winning team.',\n",
       " 'documents': [Document(metadata={}, page_content='Now, the ICC ODI Cricket World Cup is concluding with the final scheduled for November 19, 2023. Now that the league stage is over, **India, Australia, South Africa, and New Zealand** have topped the table. The first semi-final took place between India and New Zealand, with India emerging victorious by 70 runs. The second semi-final between Australia and South Africa will determine the finalists for the World Cup 2023 final. [...] As you can see, Australia is the most successful team in the history of the \\xa0ICC men’s ODI Cricket World Cup 2023, having won the tournament 5 times. India and West Indies are the only other countries to have won the World Cup more than once, with two victories each. England won the 2019 World Cup, their first-ever victory in the tournament.\\n\\nODI Cricket World Cup Winners list, Country Wise\\n------------------------------------------------ [...] As you know the ODI Cricket World Cup 2024 is concluded on 19th November 2023 and **Australia** won the World Cup final. The 2023 ICC Men’s Cricket World Cup is the 13th edition of the Cricket World Cup, a quadrennial One Day International (ODI) cricket tournament contested by men’s national teams and organized by the International Cricket Council (ICC).'),\n",
       "  Document(metadata={}, page_content='Australia secured an easy victory over India in the final match of the 2023 ICC World Cup and lifted their sixth CWC trophy.'),\n",
       "  Document(metadata={}, page_content='### Final\\n\\n|  |\\n| --- |\\n| 19 November 2023  14:00 ([D/N](/wiki/Day/night_cricket \"Day/night cricket\"))  [Scorecard](https://www.espncricinfo.com/ci/engine/match/1384439.html) |\\n\\n|  |  |  |\\n| --- | --- | --- |\\n| **[India](/wiki/India_national_cricket_team \"India national cricket team\")** 240 (50 overs) | **v** | **[Australia](/wiki/Australia_national_cricket_team \"Australia national cricket team\")** 241/4 (43 overs) |\\n|  |  |  | [...] |  |\\n| --- |\\n| 16 November 2023  14:00 ([D/N](/wiki/Day/night_cricket \"Day/night cricket\"))  [Scorecard](https://www.espncricinfo.com/ci/engine/match/1384438.html) |\\n\\n|  |  |  |\\n| --- | --- | --- |\\n| **[South Africa](/wiki/South_Africa_national_cricket_team \"South Africa national cricket team\")** 212 (49.4 overs) | **v** | **[Australia](/wiki/Australia_national_cricket_team \"Australia national cricket team\")** 215/7 (47.2 overs) |\\n|  |  |  | [...] |  |\\n| --- |\\n| 18 October 2023  [Scorecard](https://www.espncricinfo.com/ci/engine/match/1384407.html) |\\n\\n|  |  |  |\\n| --- | --- | --- |\\n| **[New Zealand](/wiki/New_Zealand_national_cricket_team \"New Zealand national cricket team\")** 288/6 (50 overs) | **v** | **[Afghanistan](/wiki/Afghanistan_national_cricket_team \"Afghanistan national cricket team\")** 139 (34.4 overs) |\\n|  |  |  |')],\n",
       " 'generation': ' The winning team of the 2023 ICC World Cup is Australia.',\n",
       " 'web_search': 'yes'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4faf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
